{"class":"org.apache.spark.ml.feature.RegexTokenizer","timestamp":1541856278566,"sparkVersion":"2.2.0","uid":"regexTok_98a8c5414a04","paramMap":{"inputCol":"text","pattern":"\\W+","toLowercase":true,"gaps":true,"outputCol":"tokens","minTokenLength":1}}
